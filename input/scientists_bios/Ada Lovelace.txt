# Convert rag_results to the format expected by RAGAS
dataset = []
for _, row in rag_results.iterrows():
    dataset.append({
        "user_input": row["question"],
        "retrieved_contexts": [row["context"]],  # RAGAS expects a list of contexts
        "response": row["response"],
        "reference": row["reference"]
    })

# Create RAGAS evaluation dataset
from ragas import EvaluationDataset
evaluation_dataset = EvaluationDataset.from_list(dataset)

# Evaluate using RAGAS metrics
from ragas import evaluate
from ragas.llms import LangchainLLMWrapper
from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness

evaluator_llm = LangchainLLMWrapper(llm)
result = evaluate(
    dataset=evaluation_dataset,
    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],
    llm=evaluator_llm
)

print(result)
